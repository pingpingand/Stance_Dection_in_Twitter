fi = ['hkx_tweet_trans_30.csv', 'hkx_tweet_trans_31.csv', 'hkx_tweet_trans_32.csv', 'hkx_tweet_trans_33.csv',
         'hkx_tweet_trans_34.csv', 'hkx_tweet_trans_35.csv', 'hkx_tweet_trans_36.csv', 'hkx_tweet_trans_37.csv',
         'hkx_tweet_trans_38.csv', 'hkx_tweet_trans_39.csv', 'hkx_tweet_trans_40.csv', 'hkx_tweet_trans_41.csv',
         'hkx_tweet_trans_42.csv', 'hkx_tweet_trans_43.csv', 'hkx_tweet_trans_44.csv', 'hkx_tweet_trans_45.csv',
         'hkx_tweet_trans_46.csv', 'hkx_tweet_trans_47.csv', 'hkx_tweet_trans_48.csv', 'hkx_tweet_trans_49.csv',
         'hkx_tweet_trans_50.csv', 'hkx_tweet_trans_51.csv', 'hkx_tweet_trans_52.csv', 'hkx_tweet_trans_53.csv',
         'hkx_tweet_trans_54.csv', 'hkx_tweet_trans_55.csv', 'hkx_tweet_trans_56.csv', 'hkx_tweet_trans_57.csv',
         'hkx_tweet_trans_58.csv', 'hkx_tweet_trans_59.csv', 'hkx_tweet_trans_60.csv', 'hkx_tweet_trans_61.csv',
         'hkx_tweet_trans_62.csv', 'hkx_tweet_trans_63.csv', 'hkx_tweet_trans_64.csv', 'hkx_tweet_trans_65.csv',
         'hkx_tweet_trans_66.csv', 'hkx_tweet_trans_67.csv', 'hkx_tweet_trans_68.csv', 'hkx_tweet_trans_69.csv',
         'hkx_tweet_trans_70.csv', 'hkx_tweet_trans_71.csv', 'hkx_tweet_trans_72.csv', 'hkx_tweet_trans_73.csv',
         'hkx_tweet_trans_74.csv', 'hkx_tweet_trans_75.csv', 'hkx_tweet_trans_76.csv', 'hkx_tweet_trans_77.csv',
         'hkx_tweet_trans_78.csv', 'hkx_tweet_trans_79.csv', 'hkx_tweet_trans_80.csv', 'hkx_tweet_trans_81.csv',
         'hkx_tweet_trans_82.csv', 'hkx_tweet_trans_83.csv', 'hkx_tweet_trans_84.csv', 'hkx_tweet_trans_85.csv',
         'hkx_tweet_trans_86.csv', 'hkx_tweet_trans_87.csv', 'hkx_tweet_trans_88.csv', 'hkx_tweet_trans_89.csv',
         'hkx_tweet_trans_90.csv', 'hkx_tweet_trans_91.csv', 'hkx_tweet_trans_92.csv', 'hkx_tweet_trans_93.csv',
         'hkx_tweet_trans_94.csv', 'hkx_tweet_trans_95.csv', 'hkx_tweet_trans_96.csv', 'hkx_tweet_trans_97.csv',
         'hkx_tweet_trans_98.csv', 'hkx_tweet_trans_99.csv', 'hkx_tweet_trans_100.csv', 'hkx_tweet_trans_101.csv',
         'hkx_tweet_trans_102.csv', 'hkx_tweet_trans_103.csv', 'hkx_tweet_trans_104.csv', 'hkx_tweet_trans_105.csv',
         'hkx_tweet_trans_106.csv', 'hkx_tweet_trans_107.csv', 'hkx_tweet_trans_108.csv', 'hkx_tweet_trans_109.csv',
         'hkx_tweet_trans_110.csv', 'hkx_tweet_trans_111.csv', 'hkx_tweet_trans_112.csv', 'hkx_tweet_trans_113.csv',
         'hkx_tweet_trans_114.csv', 'hkx_tweet_trans_115.csv', 'hkx_tweet_trans_116.csv', 'hkx_tweet_trans_117.csv',
         'hkx_tweet_trans_118.csv', 'hkx_tweet_trans_119.csv''hkx_tweet_trans_0.csv', 'hkx_tweet_trans_1.csv',
         'hkx_tweet_trans_2.csv', 'hkx_tweet_trans_3.csv',
         'hkx_tweet_trans_4.csv', 'hkx_tweet_trans_5.csv', 'hkx_tweet_trans_6.csv', 'hkx_tweet_trans_7.csv',
         'hkx_tweet_trans_8.csv', 'hkx_tweet_trans_9.csv', 'hkx_tweet_trans_10.csv', 'hkx_tweet_trans_11.csv',
         'hkx_tweet_trans_12.csv', 'hkx_tweet_trans_13.csv', 'hkx_tweet_trans_14.csv', 'hkx_tweet_trans_15.csv',
         'hkx_tweet_trans_16.csv', 'hkx_tweet_trans_17.csv', 'hkx_tweet_trans_18.csv', 'hkx_tweet_trans_19.csv',
         'hkx_tweet_trans_20.csv', 'hkx_tweet_trans_21.csv', 'hkx_tweet_trans_22.csv', 'hkx_tweet_trans_23.csv',
         'hkx_tweet_trans_24.csv', 'hkx_tweet_trans_25.csv', 'hkx_tweet_trans_26.csv', 'hkx_tweet_trans_27.csv',
         'hkx_tweet_trans_28.csv', 'hkx_tweet_trans_29.csv',
        ]


import random
from random import randint


keywords = ['parade', 'government', 'protesters', 'communist', 'communism',
            'demonstration', 'chief executive', 'conflict', 'democracy',
            'independence', 'independent', 'crisis', 'crimes', 'democratization',
            'revolution', 'protest', 'freedom', 'justice', 'violent', 'violence',
            'thugs', 'demonstrates', 'security', 'democratic', 'demonstrators', 'police',
            'extradition', 'legislative', 'political', 'arrest', 'riot', 'security', 'peace', 'vicious',
            'suppressed', 'authentic', 'administrative secretary', 'mask', 'participants', 'mob', 'authorities',
            'lin zheng', 'ministry', 'one country', 'two systems', 'mess', 'ccp',
            'prc', 'reviving', 'revive',  'restore', 'terrorism', 'freehong kong', 'free hong kong', 'movement',
            'situation', 'citizen',
            'propaganda', 'xi jinping', 'young people', 'demo', 'safety',
            'crackdown', 'gather', 'regulation', 'support', 'turmoil', 'anti delivery', 'retreat', 'march'
            ]

wgwords = ['japan', 'yen', 'disney', 'india', 'taiwan', 'macao', 'soccer game', 'stock market', 'sydney',
           'stock exchange', 'foreign exchange', 'umbrella', 'anmen square', 'london', 'hong kong sim',
           'bonus', 'korean', 'consumption tax', '1989', 'salary', 'world_cup', 'world cup', 'iran', 'thailand',
           'music', 'tourism', 'vacation', 'discount', 'singapore', 'okinawa', 'moscow', 'sign the petition',
           'lithuania', 'economy', 'russia', 'atlanta', 'nepal', 'suvarnabhumi', 'hsbc', 'financial', 'got7',
           'amsterdam', 'tiananmen', 'yokohama', 'exchange rate', 'british', 'busan', 'german', 'korea',
           'iraq', 'syria', 'yokohama', 'seoul', 'munemanteu', 'takunpao', 'shishimaru', 'chikwa', 'sing', 'liuhecai',
           'fast three', 'external model', 'film festuval', 'golden ring award', 'breaking news', 'scmp', 'udn.com',
           'investor', 'mychinanews', 'yomiuri shimbun online', 'smartnews', 'hansen index', 'money 18', 'theinitium',
           'afpbb', 'exploon', 'woachinese', 'lihkg', 'www.3.nhk', 'www.it.com', 'shimenan.xsrv', 'sankei', 'dlvr.it',
           'nikkei', 'on.wsj', 'www.nnews', 'ift.tt', 'nytimes', 'complexmatter', 'www.ntdtv', 'dwnews',
           'headline daily', 'goo.gl', 'rthk', 'lvv2.com', 'goo.gl', 'afp', 'trad.cn.rfi', 'buff.ly', 'bannedbook',
           'talk.ltn', 'sbs.com', 'cctv one minute', 'gnai.co'
           ]



for file in files2:

    oldf = open('./trans_twitter/' + file, 'r', encoding='UTF-8')
    newf = open('./trans_guolv/guolv' + file, 'w', encoding='UTF-8')
    n = 0
    lv = 0  # 过滤后的数量
    j = 0  # 原数量

    flag = 0
    lines = oldf.readlines()

    # for i in range(0,len(list(lines)),2):
    for i in range(0, len(list(lines))):
        j = j + 1
        flag = 0

        for word in keywords:
            if (word in lines[i].lower()):
                flag = 1
        if (flag == 1):
            for word in wgwords:
                if (word in lines[i].lower()):
                    flag = 0

        if (flag == 1):
            num = 0
            text = lines[i]
            words = text.split()
            for wordi in words:
                # print(word)
                num = num + 1
            if (num >= 100):
                flag = 0

        if (flag == 1):
            lv = lv + 1
            newf.write(lines[i])
        elif (flag == 0):
            # print('******************************************', j)
            # print(lines[i])
            pass

        # #     newf.write('\n')
        # newf.write(lines[i])
        # newf.write('\n')

    # print(file)
    #
    # print('j:', j)
    # print('lv:', lv)

    oldf.close()
    newf.close()




